{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zk-Hmh53Vjx9"
   },
   "source": [
    "# News Recommender System\n",
    "\n",
    "This a Google Colab for our project for the AI Course at UCU, 2021.\n",
    "\n",
    "**Authors**: Dmytro Lopushanskyy, Volodymyr Savchuk.\n",
    "\n",
    "The report for this project will be attached separately on CMS.\n",
    "\n",
    "Here is a list of materials that helped us create this project:\n",
    "\n",
    "* [MIND Data set](https://msnews.github.io/)\n",
    "* [Build Recommendation Engine](https://realpython.com/build-recommendation-engine-collaborative-filtering/)\n",
    "* [Recommender Systems in Python](https://www.kaggle.com/gspmoreira/recommender-systems-in-python-101#Recommender-Systems-in-Python-101)\n",
    "* [MIND Recommendation Notebook](https://www.kaggle.com/accountstatus/mind-microsoft-news-recommendation-v2/notebook#Text-Preprocessing)\n",
    "* [Evaluating Recommender Systems](http://fastml.com/evaluating-recommender-systems/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ha8qabqMmRZs"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "rQcv2w0LYyCm"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import sklearn\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from wordcloud import WordCloud\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zbt6l7pT0avn",
    "outputId": "c223f18c-796f-425a-d6ba-992edb8574ba"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/vozak16/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/vozak16/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/vozak16/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_behaviors = pd.read_csv('files/filtered_behaviours.csv', sep='\\t')\n",
    "\n",
    "filtered_articles = pd.read_csv('files/filtered_articles.csv', sep='\\t')\n",
    "\n",
    "behaviours_train_indexed_df = pd.read_csv('files/train_filtered_behaviours.csv', sep='\\t')\n",
    "behaviours_test_indexed_df = pd.read_csv('files/test_filtered_behaviours.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WqNQJFoCzUmb"
   },
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "5YjD7LzYzRxa"
   },
   "outputs": [],
   "source": [
    "# This function is to remove stopwords from a particular column and to tokenize it\n",
    "def rem_stopwords_tokenize(data,name):\n",
    "      \n",
    "    def getting(sen):\n",
    "        example_sent = sen\n",
    "\n",
    "        stop_words = set(stopwords.words('english')) \n",
    "\n",
    "        word_tokens = word_tokenize(example_sent) \n",
    "\n",
    "        filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
    "\n",
    "        filtered_sentence = [] \n",
    "\n",
    "        for w in word_tokens: \n",
    "            if w not in stop_words: \n",
    "                filtered_sentence.append(w) \n",
    "        return filtered_sentence\n",
    "    x=[]\n",
    "    for i in data[name].values:\n",
    "        x.append(getting(i))\n",
    "    data[name]=x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "TWwNAYkbzYT1"
   },
   "outputs": [],
   "source": [
    "# Making a function to lemmatize all the words\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "def lemmatize_all(data,name):\n",
    "    arr = data[name]\n",
    "    a = []\n",
    "    for i in arr:\n",
    "        b = []\n",
    "        for j in i:\n",
    "            x = lemmatizer.lemmatize(j,pos='a')\n",
    "            x = lemmatizer.lemmatize(x)\n",
    "            b.append(x)\n",
    "        a.append(b)\n",
    "    data[name] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "apywUaSZ6vEw"
   },
   "outputs": [],
   "source": [
    "def convert_to_string(data,name):\n",
    "    t=data[name].values\n",
    "    p=[]\n",
    "    for i in t:\n",
    "        listToStr = ' '.join(map(str, i))\n",
    "        p.append(listToStr)\n",
    "    data[name]=p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "HCU8Vat2zYF9"
   },
   "outputs": [],
   "source": [
    "# Removing Stop words from Title Column\n",
    "rem_stopwords_tokenize(filtered_articles, 'Title')\n",
    "\n",
    "# Lemmatizing the Title column\n",
    "lemmatize_all(filtered_articles, 'Title')\n",
    "\n",
    "# Back to string\n",
    "convert_to_string(filtered_articles, 'Title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "5Z9cfs36z5Y5"
   },
   "outputs": [],
   "source": [
    "# Removing Stop words from Abstract Column\n",
    "rem_stopwords_tokenize(filtered_articles, 'Abstract')\n",
    "\n",
    "# Lemmatizing the Abstract column\n",
    "lemmatize_all(filtered_articles, 'Abstract')\n",
    "\n",
    "# Back to string\n",
    "convert_to_string(filtered_articles, 'Abstract')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8chjsjJ-5hsH"
   },
   "source": [
    "## Content-Based Filtering model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MErf3RMytcqV"
   },
   "source": [
    "Create a vectorizer on behaviours train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ka6rrBXLyrZI",
    "outputId": "86a911ff-6953-4d53-8bf2-38f5d8e032b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<39726x1596 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 586288 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ignoring stopwords (words with no semantics) from English\n",
    "stopwords_list = stopwords.words('english')\n",
    "\n",
    "# Trains a model whose vectors size is 5000, composed by the main unigrams and bigrams found in the corpus, ignoring stopwords\n",
    "vectorizer = TfidfVectorizer(analyzer='word',\n",
    "                     ngram_range=(1, 2),\n",
    "                     min_df=0.003,\n",
    "                     max_df=0.5,\n",
    "                     max_features=5000,\n",
    "                     stop_words=stopwords_list)\n",
    "\n",
    "item_ids = filtered_articles['NewsID'].tolist()\n",
    "tfidf_matrix = vectorizer.fit_transform(filtered_articles['Title'] + \"\" + filtered_articles['Abstract'])\n",
    "tfidf_feature_names = vectorizer.get_feature_names()\n",
    "tfidf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "jJf9qaYb6i-B"
   },
   "outputs": [],
   "source": [
    "def get_item_profile(item_id):\n",
    "    # get a single item feature list by ID\n",
    "    try:\n",
    "        idx = item_ids.index(item_id)\n",
    "    except:\n",
    "        return None\n",
    "    item_profile = tfidf_matrix[idx:idx+1]\n",
    "    return item_profile\n",
    "\n",
    "def get_item_profiles(ids):\n",
    "    # get item vector given all item IDs that user clicked\n",
    "    item_profiles_list = [get_item_profile(x) for x in ids if x]\n",
    "    item_profiles = scipy.sparse.vstack(item_profiles_list)\n",
    "    return item_profiles\n",
    "\n",
    "def build_users_profile(person_id, interactions_df):\n",
    "    # build feature vector for a single user\n",
    "\n",
    "    # aggregate all news a user has clicked\n",
    "    interactions_person_df = interactions_df.loc[person_id]\n",
    "    user_item_profiles = get_item_profiles(interactions_person_df['All_History'])\n",
    "\n",
    "    if user_item_profiles.shape[1] == 0:\n",
    "        return None\n",
    "    user_item_strengths = np.array([1] * user_item_profiles.shape[1])\n",
    "    # Weighted average of item profiles by the interactions strength\n",
    "    user_item_strengths_weighted_avg = np.sum(user_item_profiles.multiply(user_item_strengths), axis=0) / np.sum(user_item_strengths)\n",
    "    user_profile_norm = sklearn.preprocessing.normalize(user_item_strengths_weighted_avg)\n",
    "    return user_profile_norm\n",
    "\n",
    "\n",
    "def build_users_profiles(): \n",
    "    # build a global martix of features for all users on TRAIN data set\n",
    "\n",
    "    user_profiles = {}\n",
    "    for person_id in history_train_indexed_df.index.unique():\n",
    "        user_profile = build_users_profile(person_id, history_train_indexed_df)\n",
    "        if user_profile is not None:\n",
    "            user_profiles[person_id] = user_profile\n",
    "        else:\n",
    "            print(f\"No data for user {person_id}\")\n",
    "    return user_profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "2os6GRxp710q"
   },
   "outputs": [],
   "source": [
    "user_profiles = build_users_profiles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8pbDCmaH_rRY",
    "outputId": "0a0ad4a0-3bd5-4862-b978-af738af3b8b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39718"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 695
    },
    "id": "fjolSn4iQPya",
    "outputId": "4930160b-9d78-4924-e1f7-5a17f7293b06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1596)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>car</td>\n",
       "      <td>0.300643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ford</td>\n",
       "      <td>0.231713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>look</td>\n",
       "      <td>0.166949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>celebrity</td>\n",
       "      <td>0.162159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sold</td>\n",
       "      <td>0.147832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>year</td>\n",
       "      <td>0.140770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>speed</td>\n",
       "      <td>0.132169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>star</td>\n",
       "      <td>0.130971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>home</td>\n",
       "      <td>0.129266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>halloween</td>\n",
       "      <td>0.116225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>american</td>\n",
       "      <td>0.114974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>truck</td>\n",
       "      <td>0.113156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>one</td>\n",
       "      <td>0.112146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019</td>\n",
       "      <td>0.110024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20</td>\n",
       "      <td>0.109205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>like</td>\n",
       "      <td>0.107083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>old</td>\n",
       "      <td>0.105650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>best</td>\n",
       "      <td>0.100367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>moment</td>\n",
       "      <td>0.099530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>world</td>\n",
       "      <td>0.099263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        token  relevance\n",
       "0         car   0.300643\n",
       "1        ford   0.231713\n",
       "2        look   0.166949\n",
       "3   celebrity   0.162159\n",
       "4        sold   0.147832\n",
       "5        year   0.140770\n",
       "6       speed   0.132169\n",
       "7        star   0.130971\n",
       "8        home   0.129266\n",
       "9   halloween   0.116225\n",
       "10   american   0.114974\n",
       "11      truck   0.113156\n",
       "12        one   0.112146\n",
       "13       2019   0.110024\n",
       "14         20   0.109205\n",
       "15       like   0.107083\n",
       "16        old   0.105650\n",
       "17       best   0.100367\n",
       "18     moment   0.099530\n",
       "19      world   0.099263"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_user_id = 'U1014'\n",
    "\n",
    "myprofile = user_profiles[my_user_id]\n",
    "print(myprofile.shape)\n",
    "pd.DataFrame(sorted(zip(tfidf_feature_names, \n",
    "                        user_profiles[my_user_id].flatten().tolist()), key=lambda x: -x[1])[:20],\n",
    "             columns=['token', 'relevance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "MBPFBNQQQ9bq"
   },
   "outputs": [],
   "source": [
    "class ContentBasedRecommender:\n",
    "    MODEL_NAME = 'Content-Based'\n",
    "    \n",
    "    def __init__(self, items_df=None):\n",
    "        self.item_ids = item_ids\n",
    "        self.items_df = items_df\n",
    "        \n",
    "    def get_model_name(self):\n",
    "        return self.MODEL_NAME\n",
    "        \n",
    "    def _get_similar_items_to_user_profile(self, person_id, topn=1000):\n",
    "        # Computes the cosine similarity between the user profile and all item profiles\n",
    "        cosine_similarities = cosine_similarity(user_profiles[person_id], tfidf_matrix)\n",
    "        # Gets the top similar items\n",
    "        similar_indices = cosine_similarities.argsort().flatten()[-topn:]\n",
    "        # Sort the similar items by similarity\n",
    "        similar_items = sorted([(item_ids[i], cosine_similarities[0,i]) for i in similar_indices], key=lambda x: -x[1])\n",
    "        return similar_items\n",
    "        \n",
    "    def recommend_items(self, user_id, items_to_ignore=[], topn=10, ignore_interacted=True, verbose=False):\n",
    "        similar_items = self._get_similar_items_to_user_profile(user_id, topn)\n",
    "        # Ignores items the user has already interacted\n",
    "        if ignore_interacted:\n",
    "            similar_items = list(filter(lambda x: x[0] not in items_to_ignore, similar_items))\n",
    "        \n",
    "        recommendations_df = pd.DataFrame(similar_items, columns=['NewsID', 'recStrength']) \\\n",
    "                                    .head(topn)\n",
    "\n",
    "        if verbose:\n",
    "            if self.items_df is None:\n",
    "                raise Exception('\"items_df\" is required in verbose mode')\n",
    "\n",
    "            recommendations_df = recommendations_df.merge(self.items_df, how = 'left', \n",
    "                                                          left_on = 'contentId', \n",
    "                                                          right_on = 'contentId')[['recStrength', 'contentId', 'title', 'url', 'lang']]\n",
    "\n",
    "\n",
    "        return recommendations_df\n",
    "    \n",
    "content_based_recommender_model = ContentBasedRecommender(filtered_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HXEXoTXMZsff"
   },
   "source": [
    "### Recommendations for a single user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "id": "Q06aXgo5Tple",
    "outputId": "cf127de4-f68f-4650-b246-32410aaee0a3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NewsID</th>\n",
       "      <th>recStrength</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Category</th>\n",
       "      <th>SubCategory</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N1375</td>\n",
       "      <td>0.354892</td>\n",
       "      <td>35773</td>\n",
       "      <td>autos</td>\n",
       "      <td>autosnews</td>\n",
       "      <td>Those classic Shelby race car 'Ford v Ferrari ...</td>\n",
       "      <td>But n't call `` replica '' `` kit car . ''</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N58544</td>\n",
       "      <td>0.317736</td>\n",
       "      <td>21382</td>\n",
       "      <td>video</td>\n",
       "      <td>science</td>\n",
       "      <td>Tiny Electric Car Cost $ 420,000 To Build</td>\n",
       "      <td>A MAN claim created car might solve world 's t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N1942</td>\n",
       "      <td>0.304930</td>\n",
       "      <td>28957</td>\n",
       "      <td>autos</td>\n",
       "      <td>autossports</td>\n",
       "      <td>2020 Ford Mustang Shelby GT500 Is 760-HP Thril...</td>\n",
       "      <td>Ford 's ultimate pony car finely honed blast r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N35346</td>\n",
       "      <td>0.302405</td>\n",
       "      <td>31031</td>\n",
       "      <td>autos</td>\n",
       "      <td>autosenthusiasts</td>\n",
       "      <td>This 1965 Ford Mustang Fastback On A Ford Bron...</td>\n",
       "      <td>The Frankensteinian result may pinnacle four-w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N3345</td>\n",
       "      <td>0.300671</td>\n",
       "      <td>21047</td>\n",
       "      <td>autos</td>\n",
       "      <td>autosclassics</td>\n",
       "      <td>Man Reveals Big American Muscle Car Barn Find</td>\n",
       "      <td>These classic car definitely showroom condition .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>N25845</td>\n",
       "      <td>0.300362</td>\n",
       "      <td>12264</td>\n",
       "      <td>news</td>\n",
       "      <td>newsus</td>\n",
       "      <td>1 killed , 3 seriously hurt racing car crash u...</td>\n",
       "      <td>One person killed three others seriously injur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>N42208</td>\n",
       "      <td>0.289972</td>\n",
       "      <td>10898</td>\n",
       "      <td>autos</td>\n",
       "      <td>autosclassics</td>\n",
       "      <td>U.S . Marshals Auctioning Off 149 Vehicles Fro...</td>\n",
       "      <td>The large single car collection USMS ever sold !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>N37859</td>\n",
       "      <td>0.288046</td>\n",
       "      <td>34764</td>\n",
       "      <td>autos</td>\n",
       "      <td>autosclassics</td>\n",
       "      <td>Icon 's electric 1949 Mercury V8-powered 1949 ...</td>\n",
       "      <td>These no-expense-spared custom car California ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>N15719</td>\n",
       "      <td>0.285456</td>\n",
       "      <td>35746</td>\n",
       "      <td>autos</td>\n",
       "      <td>autosenthusiasts</td>\n",
       "      <td>2020 Ford Mustang Shelby GT350 vs. GT500 : Whi...</td>\n",
       "      <td>Is $ 12,460 costly GT500 good sport car alread...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>N44712</td>\n",
       "      <td>0.285223</td>\n",
       "      <td>34756</td>\n",
       "      <td>news</td>\n",
       "      <td>newscrime</td>\n",
       "      <td>Car , evidence seized fatal hit-and-run invest...</td>\n",
       "      <td>A 57-year-old Methuen man struck killed car ri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NewsID  recStrength  Unnamed: 0 Category       SubCategory  \\\n",
       "0   N1375     0.354892       35773    autos         autosnews   \n",
       "1  N58544     0.317736       21382    video           science   \n",
       "2   N1942     0.304930       28957    autos       autossports   \n",
       "3  N35346     0.302405       31031    autos  autosenthusiasts   \n",
       "4   N3345     0.300671       21047    autos     autosclassics   \n",
       "5  N25845     0.300362       12264     news            newsus   \n",
       "6  N42208     0.289972       10898    autos     autosclassics   \n",
       "7  N37859     0.288046       34764    autos     autosclassics   \n",
       "8  N15719     0.285456       35746    autos  autosenthusiasts   \n",
       "9  N44712     0.285223       34756     news         newscrime   \n",
       "\n",
       "                                               Title  \\\n",
       "0  Those classic Shelby race car 'Ford v Ferrari ...   \n",
       "1          Tiny Electric Car Cost $ 420,000 To Build   \n",
       "2  2020 Ford Mustang Shelby GT500 Is 760-HP Thril...   \n",
       "3  This 1965 Ford Mustang Fastback On A Ford Bron...   \n",
       "4      Man Reveals Big American Muscle Car Barn Find   \n",
       "5  1 killed , 3 seriously hurt racing car crash u...   \n",
       "6  U.S . Marshals Auctioning Off 149 Vehicles Fro...   \n",
       "7  Icon 's electric 1949 Mercury V8-powered 1949 ...   \n",
       "8  2020 Ford Mustang Shelby GT350 vs. GT500 : Whi...   \n",
       "9  Car , evidence seized fatal hit-and-run invest...   \n",
       "\n",
       "                                            Abstract  \n",
       "0         But n't call `` replica '' `` kit car . ''  \n",
       "1  A MAN claim created car might solve world 's t...  \n",
       "2  Ford 's ultimate pony car finely honed blast r...  \n",
       "3  The Frankensteinian result may pinnacle four-w...  \n",
       "4  These classic car definitely showroom condition .  \n",
       "5  One person killed three others seriously injur...  \n",
       "6   The large single car collection USMS ever sold !  \n",
       "7  These no-expense-spared custom car California ...  \n",
       "8  Is $ 12,460 costly GT500 good sport car alread...  \n",
       "9  A 57-year-old Methuen man struck killed car ri...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recs = content_based_recommender_model.recommend_items(my_user_id)\n",
    "recs.set_index('NewsID')\n",
    "pd.merge(recs, filtered_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "noVOdKnwQUfL"
   },
   "source": [
    "## Evaluation Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "aRev-YH9kGRX"
   },
   "outputs": [],
   "source": [
    "def get_items_interacted(person_id, interactions_df):\n",
    "    # Get the user's data and merge in the news information.\n",
    "    interacted_items = interactions_df.loc[person_id]['NewsID']\n",
    "    return set(interacted_items if type(interacted_items) == pd.Series else [interacted_items])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JPBMK82zq1X4",
    "outputId": "840e0dc2-e087-40db-be69-b318e993479b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39726, 6)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_articles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "vlWB2mubmjiY"
   },
   "outputs": [],
   "source": [
    "# Top-N accuracy metrics consts\n",
    "EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS = 100\n",
    "\n",
    "class ModelEvaluator:\n",
    "    def get_not_interacted_items_sample(self, person_id, sample_size, seed=42):\n",
    "        interacted_items = get_items_interacted(person_id, behaviours_full_indexed_df)\n",
    "        all_items = set(filtered_articles['NewsID'])\n",
    "        non_interacted_items = all_items - interacted_items\n",
    "\n",
    "        random.seed(seed)\n",
    "        non_interacted_items_sample = random.sample(non_interacted_items, sample_size)\n",
    "        return set(non_interacted_items_sample)\n",
    "\n",
    "    def _verify_hit_top_n(self, item_id, recommended_items, topn):      \n",
    "        try:\n",
    "            index = next(i for i, c in enumerate(recommended_items) if c == item_id)\n",
    "        except Exception as e:\n",
    "            index = -1\n",
    "        hit = int(index in range(0, topn))\n",
    "        return hit, index\n",
    "\n",
    "    def evaluate_model_for_user(self, model, person_id):\n",
    "        # Getting the items in test set\n",
    "        interacted_values_testset = behaviours_test_indexed_df.loc[person_id]\n",
    "        if type(interacted_values_testset['NewsID']) == pd.Series:\n",
    "            person_interacted_items_testset = set(interacted_values_testset['NewsID'])\n",
    "        else:\n",
    "            person_interacted_items_testset = set([interacted_values_testset['NewsID']])  \n",
    "        interacted_items_count_testset = len(person_interacted_items_testset) \n",
    "\n",
    "        # Getting a ranked recommendation list from a model for a given user\n",
    "        person_recs_df = model.recommend_items(\n",
    "            person_id, \n",
    "            items_to_ignore=get_items_interacted(person_id, behaviours_train_indexed_df), \n",
    "            topn=10000000000, ignore_interacted=False)\n",
    "        \n",
    "        hits_at_5_count = 0\n",
    "        hits_at_10_count = 0\n",
    "        # For each item the user has interacted in test set\n",
    "        for item_id in person_interacted_items_testset:\n",
    "            # Getting a random sample (100) items the user has not interacted \n",
    "            # (to represent items that are assumed to be no relevant to the user)\n",
    "            non_interacted_items_sample = self.get_not_interacted_items_sample(person_id, \n",
    "                                                                          sample_size=EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS, \n",
    "                                                                          seed=random.randint(0, 2**32))\n",
    "\n",
    "            # Combining the current interacted item with the 100 random items\n",
    "            items_to_filter_recs = non_interacted_items_sample.union(set([item_id]))\n",
    "\n",
    "            # Filtering only recommendations that are either the interacted item or from a random sample of 100 non-interacted items\n",
    "            valid_recs_df = person_recs_df[person_recs_df['NewsID'].isin(items_to_filter_recs)]                    \n",
    "            valid_recs = valid_recs_df['NewsID'].values\n",
    "            # Verifying if the current interacted item is among the Top-N recommended items\n",
    "            hit_at_5, index_at_5 = self._verify_hit_top_n(item_id, valid_recs, 5)\n",
    "            hits_at_5_count += hit_at_5\n",
    "            hit_at_10, index_at_10 = self._verify_hit_top_n(item_id, valid_recs, 10)\n",
    "            hits_at_10_count += hit_at_10\n",
    "\n",
    "        # Recall is the rate of the interacted items that are ranked among the Top-N recommended items, \n",
    "        # when mixed with a set of non-relevant items\n",
    "        recall_at_5 = hits_at_5_count / float(interacted_items_count_testset)\n",
    "        recall_at_10 = hits_at_10_count / float(interacted_items_count_testset)\n",
    "\n",
    "        person_metrics = {'hits@5_count': hits_at_5_count, \n",
    "                          'hits@10_count': hits_at_10_count, \n",
    "                          'interacted_count': interacted_items_count_testset,\n",
    "                          'recall@5': recall_at_5,\n",
    "                          'recall@10': recall_at_10}\n",
    "        return person_metrics\n",
    "\n",
    "    def evaluate_model(self, model):\n",
    "        print('Running evaluation for users')\n",
    "        people_metrics = []\n",
    "        for idx, person_id in enumerate(list(behaviours_test_indexed_df.index.unique().values)):\n",
    "            if idx % 100 == 0 and idx > 0:\n",
    "               print('%d users processed' % idx)\n",
    "            person_metrics = self.evaluate_model_for_user(model, person_id)  \n",
    "            person_metrics['_person_id'] = person_id\n",
    "            people_metrics.append(person_metrics)\n",
    "        print('%d users processed' % idx)\n",
    "\n",
    "        detailed_results_df = pd.DataFrame(people_metrics) \\\n",
    "                            .sort_values('interacted_count', ascending=False)\n",
    "        \n",
    "        global_recall_at_5 = detailed_results_df['hits@5_count'].sum() / float(detailed_results_df['interacted_count'].sum())\n",
    "        global_recall_at_10 = detailed_results_df['hits@10_count'].sum() / float(detailed_results_df['interacted_count'].sum())\n",
    "        \n",
    "        global_metrics = {'modelName': model.get_model_name(),\n",
    "                          'recall@5': global_recall_at_5,\n",
    "                          'recall@10': global_recall_at_10}    \n",
    "        return global_metrics, detailed_results_df\n",
    "    \n",
    "model_evaluator = ModelEvaluator()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UbwpK5txaDNE"
   },
   "source": [
    "Reduce the test data set to 3000 elements to reduce computation time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "F_RU3OWnLIM1"
   },
   "outputs": [],
   "source": [
    "behaviours_test_indexed_df_full = behaviours_test_indexed_df.copy()\n",
    "behaviours_test_indexed_df = behaviours_test_indexed_df[:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UbnyzNllLNwq",
    "outputId": "db03fc81-8397-4a8a-ef85-cf06194e6d5d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(behaviours_test_indexed_df.index.values.tolist()))\n",
    "behaviours_test_indexed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "BnsLnL_eQIaZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Content-Based Filtering model...\n",
      "Running evaluation for users\n",
      "100 users processed\n",
      "200 users processed\n",
      "300 users processed\n",
      "400 users processed\n",
      "500 users processed\n",
      "600 users processed\n",
      "700 users processed\n",
      "800 users processed\n",
      "900 users processed\n",
      "1000 users processed\n",
      "1100 users processed\n",
      "1200 users processed\n",
      "1300 users processed\n",
      "1400 users processed\n",
      "1500 users processed\n",
      "1600 users processed\n",
      "1700 users processed\n",
      "1800 users processed\n",
      "1900 users processed\n",
      "2000 users processed\n",
      "2100 users processed\n",
      "2200 users processed\n",
      "2300 users processed\n",
      "2400 users processed\n",
      "2500 users processed\n",
      "2600 users processed\n",
      "2700 users processed\n",
      "2800 users processed\n",
      "2839 users processed\n"
     ]
    }
   ],
   "source": [
    "print('Evaluating Content-Based Filtering model...')\n",
    "cb_global_metrics, cb_detailed_results_df = model_evaluator.evaluate_model(content_based_recommender_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 732
    },
    "id": "otKqK4ay15ZV",
    "outputId": "ab26a4c3-80b9-4249-e03f-4688397c6341"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Global metrics:\n",
      "{'modelName': 'Content-Based', 'recall@5': 0.16, 'recall@10': 0.238}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hits@5_count</th>\n",
       "      <th>hits@10_count</th>\n",
       "      <th>interacted_count</th>\n",
       "      <th>recall@5</th>\n",
       "      <th>recall@10</th>\n",
       "      <th>_person_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2313</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U57567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U1484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1688</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U22992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2328</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U24722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2326</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U82289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2323</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U70006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2310</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U26140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2348</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U69737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U54436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2346</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U4582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2344</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U77841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2331</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U81388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U81203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U54835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U40237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U73145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2334</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U58499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2455</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U90344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1666</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U37886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      hits@5_count  hits@10_count  interacted_count  recall@5  recall@10  \\\n",
       "2313             0              1                 1       0.0        1.0   \n",
       "1560             0              1                 1       0.0        1.0   \n",
       "1687             1              1                 1       1.0        1.0   \n",
       "1688             0              1                 1       0.0        1.0   \n",
       "2328             1              1                 1       1.0        1.0   \n",
       "2326             1              1                 1       1.0        1.0   \n",
       "2323             0              1                 1       0.0        1.0   \n",
       "2310             1              1                 1       1.0        1.0   \n",
       "2348             1              1                 1       1.0        1.0   \n",
       "1574             1              1                 1       1.0        1.0   \n",
       "2346             0              1                 1       0.0        1.0   \n",
       "2344             1              1                 1       1.0        1.0   \n",
       "2331             1              1                 1       1.0        1.0   \n",
       "1679             1              1                 1       1.0        1.0   \n",
       "1577             1              1                 1       1.0        1.0   \n",
       "1670             1              1                 1       1.0        1.0   \n",
       "1663             1              1                 1       1.0        1.0   \n",
       "2334             1              1                 1       1.0        1.0   \n",
       "2455             1              1                 1       1.0        1.0   \n",
       "1666             1              1                 1       1.0        1.0   \n",
       "\n",
       "     _person_id  \n",
       "2313       U863  \n",
       "1560     U57567  \n",
       "1687      U1484  \n",
       "1688     U22992  \n",
       "2328     U24722  \n",
       "2326     U82289  \n",
       "2323     U70006  \n",
       "2310     U26140  \n",
       "2348     U69737  \n",
       "1574     U54436  \n",
       "2346      U4582  \n",
       "2344     U77841  \n",
       "2331     U81388  \n",
       "1679     U81203  \n",
       "1577     U54835  \n",
       "1670     U40237  \n",
       "1663     U73145  \n",
       "2334     U58499  \n",
       "2455     U90344  \n",
       "1666     U37886  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('\\nGlobal metrics:\\n%s' % cb_global_metrics)\n",
    "cb_detailed_results_df.sort_values('recall@10', ascending=False).head(20)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "News Recommender System. Lopushanskyy, Savchuk.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
