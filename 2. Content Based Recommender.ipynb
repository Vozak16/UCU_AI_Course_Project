{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zk-Hmh53Vjx9"
   },
   "source": [
    "# News Recommender System\n",
    "\n",
    "This a Google Colab for our project for the AI Course at UCU, 2021.\n",
    "\n",
    "**Authors**: Dmytro Lopushanskyy, Volodymyr Savchuk.\n",
    "\n",
    "The report for this project will be attached separately on CMS.\n",
    "\n",
    "Here is a list of materials that helped us create this project:\n",
    "\n",
    "* [MIND Data set](https://msnews.github.io/)\n",
    "* [Build Recommendation Engine](https://realpython.com/build-recommendation-engine-collaborative-filtering/)\n",
    "* [Recommender Systems in Python](https://www.kaggle.com/gspmoreira/recommender-systems-in-python-101#Recommender-Systems-in-Python-101)\n",
    "* [MIND Recommendation Notebook](https://www.kaggle.com/accountstatus/mind-microsoft-news-recommendation-v2/notebook#Text-Preprocessing)\n",
    "* [Evaluating Recommender Systems](http://fastml.com/evaluating-recommender-systems/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ha8qabqMmRZs"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "rQcv2w0LYyCm"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import sklearn\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.metrics.pairwise import polynomial_kernel\n",
    "from sklearn.metrics.pairwise import manhattan_distances\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from wordcloud import WordCloud\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zbt6l7pT0avn",
    "outputId": "c223f18c-796f-425a-d6ba-992edb8574ba"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/vozak16/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/vozak16/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/vozak16/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_behaviors = pd.read_csv('files/filtered_behaviours.csv', sep='\\t')\n",
    "\n",
    "filtered_articles = pd.read_csv('files/filtered_articles.csv', sep='\\t')\n",
    "\n",
    "behaviours_train_indexed_df = pd.read_csv('files/train_filtered_behaviours.csv', sep='\\t')\n",
    "behaviours_test_indexed_df = pd.read_csv('files/test_filtered_behaviours.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gl7U76Y3tU4V"
   },
   "outputs": [],
   "source": [
    "filtered_behaviors.set_index('UserID')\n",
    "filtered_behaviors['All_History'] = filtered_behaviors.groupby(['UserID']).History.transform(lambda x: ' '.join(x)).transform(lambda x: list(set(x.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "id": "PCoBD0vAtC0f",
    "outputId": "70d520f5-9551-4b36-e7e4-fc2c20803591"
   },
   "outputs": [],
   "source": [
    "all_history = filtered_behaviors.drop_duplicates(subset=['UserID'])\n",
    "all_history = all_history.filter(['UserID', 'All_History'])\n",
    "all_history = all_history.set_index('UserID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9QrydRahiaqI"
   },
   "outputs": [],
   "source": [
    "expanded_behaviors = all_history.explode('All_History').reset_index() \n",
    "expanded_behaviors.rename(columns={'All_History': 'NewsID'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_XFDdG6HQoU_",
    "outputId": "0cf4e9d8-3f63-4a8e-e908-5bb019d33267"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# interactions on Train set: 983294\n",
      "# interactions on Test set: 245824\n"
     ]
    }
   ],
   "source": [
    "behaviours_train_df, behaviours_test_df = train_test_split(expanded_behaviors,\n",
    "                                   stratify=expanded_behaviors['UserID'], \n",
    "                                   test_size=0.20,\n",
    "                                   random_state=42)\n",
    "\n",
    "print('# interactions on Train set: %d' % len(behaviours_train_df))\n",
    "print('# interactions on Test set: %d' % len(behaviours_test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0e0W8qrBQeWS"
   },
   "outputs": [],
   "source": [
    "# Indexing by UserID to speed up the searches during evaluation\n",
    "behaviours_full_indexed_df = expanded_behaviors.set_index('UserID')\n",
    "behaviours_train_indexed_df = behaviours_train_df.set_index('UserID')\n",
    "behaviours_test_indexed_df = behaviours_test_df.set_index('UserID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VCxa_BlB4OCN"
   },
   "outputs": [],
   "source": [
    "# group by userID back to aggregated values\n",
    "history_train_indexed_df = behaviours_train_indexed_df.groupby(['UserID'])['NewsID'].apply(list).reset_index().set_index('UserID')\n",
    "history_train_indexed_df.rename(columns={'NewsID': 'All_History'}, inplace=True)\n",
    "\n",
    "history_test_indexed_df = behaviours_test_indexed_df.groupby(['UserID'])['NewsID'].apply(list).reset_index().set_index('UserID')\n",
    "history_test_indexed_df.rename(columns={'NewsID': 'All_History'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YOHulcaZ8c_d"
   },
   "outputs": [],
   "source": [
    "# implement filtering\n",
    "history_test_indexed_df = history_test_indexed_df[history_test_indexed_df.index.isin(history_train_indexed_df.index.values.tolist())]\n",
    "behaviours_test_indexed_df = behaviours_test_indexed_df[behaviours_test_indexed_df.index.isin(history_train_indexed_df.index.values.tolist())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WqNQJFoCzUmb"
   },
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "5YjD7LzYzRxa"
   },
   "outputs": [],
   "source": [
    "# This function is to remove stopwords from a particular column and to tokenize it\n",
    "def rem_stopwords_tokenize(data,name):\n",
    "      \n",
    "    def getting(sen):\n",
    "        example_sent = sen\n",
    "\n",
    "        stop_words = set(stopwords.words('english')) \n",
    "\n",
    "        word_tokens = word_tokenize(example_sent) \n",
    "\n",
    "        filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
    "\n",
    "        filtered_sentence = [] \n",
    "\n",
    "        for w in word_tokens: \n",
    "            if w not in stop_words: \n",
    "                filtered_sentence.append(w) \n",
    "        return filtered_sentence\n",
    "    x=[]\n",
    "    for i in data[name].values:\n",
    "        x.append(getting(i))\n",
    "    data[name]=x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "TWwNAYkbzYT1"
   },
   "outputs": [],
   "source": [
    "# Making a function to lemmatize all the words\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "def lemmatize_all(data,name):\n",
    "    arr = data[name]\n",
    "    a = []\n",
    "    for i in arr:\n",
    "        b = []\n",
    "        for j in i:\n",
    "            x = lemmatizer.lemmatize(j,pos='a')\n",
    "            x = lemmatizer.lemmatize(x)\n",
    "            b.append(x)\n",
    "        a.append(b)\n",
    "    data[name] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "apywUaSZ6vEw"
   },
   "outputs": [],
   "source": [
    "def convert_to_string(data,name):\n",
    "    t=data[name].values\n",
    "    p=[]\n",
    "    for i in t:\n",
    "        listToStr = ' '.join(map(str, i))\n",
    "        p.append(listToStr)\n",
    "    data[name]=p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "HCU8Vat2zYF9"
   },
   "outputs": [],
   "source": [
    "# Removing Stop words from Title Column\n",
    "rem_stopwords_tokenize(filtered_articles, 'Title')\n",
    "\n",
    "# Lemmatizing the Title column\n",
    "lemmatize_all(filtered_articles, 'Title')\n",
    "\n",
    "# Back to string\n",
    "convert_to_string(filtered_articles, 'Title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "5Z9cfs36z5Y5"
   },
   "outputs": [],
   "source": [
    "# Removing Stop words from Abstract Column\n",
    "rem_stopwords_tokenize(filtered_articles, 'Abstract')\n",
    "\n",
    "# Lemmatizing the Abstract column\n",
    "lemmatize_all(filtered_articles, 'Abstract')\n",
    "\n",
    "# Back to string\n",
    "convert_to_string(filtered_articles, 'Abstract')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8chjsjJ-5hsH"
   },
   "source": [
    "## Content-Based Filtering model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MErf3RMytcqV"
   },
   "source": [
    "### Create a vectorizer on behaviours train dataset\n",
    "\n",
    "We choose as a word embedding technique TF-IDF, also, we have tested Word2Vec, but **TF-IDF** performed better. We have analyzed different numbers of n-values for n-grams to be extracted and we concluded that **unigrams and bigrams** give the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ka6rrBXLyrZI",
    "outputId": "86a911ff-6953-4d53-8bf2-38f5d8e032b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<39726x1596 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 586288 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ignoring stopwords (words with no semantics) from English\n",
    "stopwords_list = stopwords.words('english')\n",
    "\n",
    "# Trains a model whose vectors size is 5000, composed by the main unigrams and bigrams found in the corpus, ignoring stopwords\n",
    "vectorizer = TfidfVectorizer(analyzer='word',\n",
    "                     ngram_range=(1, 2),\n",
    "                     min_df=0.003,\n",
    "                     max_df=0.5,\n",
    "                     max_features=5000,\n",
    "                     stop_words=stopwords_list)\n",
    "\n",
    "item_ids = filtered_articles['NewsID'].tolist()\n",
    "tfidf_matrix = vectorizer.fit_transform(filtered_articles['Title'] + \"\" + filtered_articles['Abstract'])\n",
    "tfidf_feature_names = vectorizer.get_feature_names()\n",
    "tfidf_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "jJf9qaYb6i-B"
   },
   "outputs": [],
   "source": [
    "def get_item_profile(item_id):\n",
    "    # get a single item feature list by ID\n",
    "    try:\n",
    "        idx = item_ids.index(item_id)\n",
    "    except:\n",
    "        return None\n",
    "    item_profile = tfidf_matrix[idx:idx+1]\n",
    "    return item_profile\n",
    "\n",
    "def get_item_profiles(ids):\n",
    "    # get item vector given all item IDs that user clicked\n",
    "    item_profiles_list = [get_item_profile(x) for x in ids if x]\n",
    "    item_profiles = scipy.sparse.vstack(item_profiles_list)\n",
    "    return item_profiles\n",
    "\n",
    "def build_users_profile(person_id, interactions_df):\n",
    "    # build feature vector for a single user\n",
    "\n",
    "    # aggregate all news a user has clicked\n",
    "    interactions_person_df = interactions_df.loc[person_id]\n",
    "    user_item_profiles = get_item_profiles(interactions_person_df['All_History'])\n",
    "\n",
    "    if user_item_profiles.shape[1] == 0:\n",
    "        return None\n",
    "    user_item_strengths = np.array([1] * user_item_profiles.shape[1])\n",
    "    # Weighted average of item profiles by the interactions strength\n",
    "    user_item_strengths_weighted_avg = np.sum(user_item_profiles.multiply(user_item_strengths), axis=0) / np.sum(user_item_strengths)\n",
    "    user_profile_norm = sklearn.preprocessing.normalize(user_item_strengths_weighted_avg)\n",
    "    return user_profile_norm\n",
    "\n",
    "\n",
    "def build_users_profiles(): \n",
    "    # build a global martix of features for all users on TRAIN data set\n",
    "    all_users_length = len(history_train_indexed_df.index.unique())\n",
    "\n",
    "    user_profiles = {}\n",
    "    for num_id, person_id in enumerate(history_train_indexed_df.index.unique()):\n",
    "        if (num_id + 1) % 1000 == 0:\n",
    "            print(\"Users processed: {} out of {}\".format(num_id + 1, all_users_length))\n",
    "        user_profile = build_users_profile(person_id, history_train_indexed_df)\n",
    "        if user_profile is not None:\n",
    "            user_profiles[person_id] = user_profile\n",
    "        else:\n",
    "            print(f\"No data for user {person_id}\")\n",
    "    return user_profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "2os6GRxp710q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users processed: 1000 out of 39718\n",
      "Users processed: 2000 out of 39718\n",
      "Users processed: 3000 out of 39718\n",
      "Users processed: 4000 out of 39718\n",
      "Users processed: 5000 out of 39718\n",
      "Users processed: 6000 out of 39718\n",
      "Users processed: 7000 out of 39718\n",
      "Users processed: 8000 out of 39718\n",
      "Users processed: 9000 out of 39718\n",
      "Users processed: 10000 out of 39718\n",
      "Users processed: 11000 out of 39718\n",
      "Users processed: 12000 out of 39718\n",
      "Users processed: 13000 out of 39718\n",
      "Users processed: 14000 out of 39718\n",
      "Users processed: 15000 out of 39718\n",
      "Users processed: 16000 out of 39718\n",
      "Users processed: 17000 out of 39718\n",
      "Users processed: 18000 out of 39718\n",
      "Users processed: 19000 out of 39718\n",
      "Users processed: 20000 out of 39718\n",
      "Users processed: 21000 out of 39718\n",
      "Users processed: 22000 out of 39718\n",
      "Users processed: 23000 out of 39718\n",
      "Users processed: 24000 out of 39718\n",
      "Users processed: 25000 out of 39718\n",
      "Users processed: 26000 out of 39718\n",
      "Users processed: 27000 out of 39718\n",
      "Users processed: 28000 out of 39718\n",
      "Users processed: 29000 out of 39718\n",
      "Users processed: 30000 out of 39718\n",
      "Users processed: 31000 out of 39718\n",
      "Users processed: 32000 out of 39718\n",
      "Users processed: 33000 out of 39718\n",
      "Users processed: 34000 out of 39718\n",
      "Users processed: 35000 out of 39718\n",
      "Users processed: 36000 out of 39718\n",
      "Users processed: 37000 out of 39718\n",
      "Users processed: 38000 out of 39718\n",
      "Users processed: 39000 out of 39718\n"
     ]
    }
   ],
   "source": [
    "user_profiles = build_users_profiles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8pbDCmaH_rRY",
    "outputId": "0a0ad4a0-3bd5-4862-b978-af738af3b8b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39718"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(user_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 695
    },
    "id": "fjolSn4iQPya",
    "outputId": "4930160b-9d78-4924-e1f7-5a17f7293b06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1596)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>car</td>\n",
       "      <td>0.342663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ford</td>\n",
       "      <td>0.207097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>celebrity</td>\n",
       "      <td>0.147849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>speed</td>\n",
       "      <td>0.128666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>one</td>\n",
       "      <td>0.121439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>build</td>\n",
       "      <td>0.121177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>0.120551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>best</td>\n",
       "      <td>0.117313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>world</td>\n",
       "      <td>0.112999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>american</td>\n",
       "      <td>0.111923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>may</td>\n",
       "      <td>0.109971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>year</td>\n",
       "      <td>0.109568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>star</td>\n",
       "      <td>0.109461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>show</td>\n",
       "      <td>0.101654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sold</td>\n",
       "      <td>0.101293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>new</td>\n",
       "      <td>0.100277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>run</td>\n",
       "      <td>0.097366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>home</td>\n",
       "      <td>0.097237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>moment</td>\n",
       "      <td>0.096892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>man</td>\n",
       "      <td>0.095003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        token  relevance\n",
       "0         car   0.342663\n",
       "1        ford   0.207097\n",
       "2   celebrity   0.147849\n",
       "3       speed   0.128666\n",
       "4         one   0.121439\n",
       "5       build   0.121177\n",
       "6          20   0.120551\n",
       "7        best   0.117313\n",
       "8       world   0.112999\n",
       "9    american   0.111923\n",
       "10        may   0.109971\n",
       "11       year   0.109568\n",
       "12       star   0.109461\n",
       "13       show   0.101654\n",
       "14       sold   0.101293\n",
       "15        new   0.100277\n",
       "16        run   0.097366\n",
       "17       home   0.097237\n",
       "18     moment   0.096892\n",
       "19        man   0.095003"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_user_id = 'U1014'\n",
    "\n",
    "myprofile = user_profiles[my_user_id]\n",
    "print(myprofile.shape)\n",
    "pd.DataFrame(sorted(zip(tfidf_feature_names, \n",
    "                        user_profiles[my_user_id].flatten().tolist()), key=lambda x: -x[1])[:20],\n",
    "             columns=['token', 'relevance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "MBPFBNQQQ9bq"
   },
   "outputs": [],
   "source": [
    "class ContentBasedRecommenderCosineSimilarity:\n",
    "    MODEL_NAME = 'Content-Based'\n",
    "    \n",
    "    def __init__(self, items_df=None):\n",
    "        self.item_ids = item_ids\n",
    "        self.items_df = items_df\n",
    "        \n",
    "    def get_model_name(self):\n",
    "        return self.MODEL_NAME\n",
    "        \n",
    "    def _get_similar_items_to_user_profile(self, person_id, topn=1000):\n",
    "        # Computes the cosine similarity between the user profile and all item profiles\n",
    "        cosine_similarities = cosine_similarity(user_profiles[person_id], tfidf_matrix)\n",
    "        # Gets the top similar items\n",
    "        similar_indices = cosine_similarities.argsort().flatten()[-topn:]\n",
    "        # Sort the similar items by similarity\n",
    "        similar_items = sorted([(item_ids[i], cosine_similarities[0,i]) for i in similar_indices], key=lambda x: -x[1])\n",
    "        return similar_items\n",
    "        \n",
    "    def recommend_items(self, user_id, items_to_ignore=[], topn=10, ignore_interacted=True, verbose=False):\n",
    "        similar_items = self._get_similar_items_to_user_profile(user_id, topn)\n",
    "        # Ignores items the user has already interacted\n",
    "        if ignore_interacted:\n",
    "            similar_items = list(filter(lambda x: x[0] not in items_to_ignore, similar_items))\n",
    "        \n",
    "        recommendations_df = pd.DataFrame(similar_items, columns=['NewsID', 'recStrength']) \\\n",
    "                                    .head(topn)\n",
    "\n",
    "        if verbose:\n",
    "            if self.items_df is None:\n",
    "                raise Exception('\"items_df\" is required in verbose mode')\n",
    "\n",
    "            recommendations_df = recommendations_df.merge(self.items_df, how = 'left', \n",
    "                                                          left_on = 'contentId', \n",
    "                                                          right_on = 'contentId')[['recStrength', 'contentId', 'title', 'url', 'lang']]\n",
    "\n",
    "\n",
    "        return recommendations_df\n",
    "\n",
    "class ContentBasedRecommenderEuclidean(ContentBasedRecommenderCosineSimilarity):\n",
    "    \n",
    "    def _get_similar_items_to_user_profile(self, person_id, topn=1000):\n",
    "        # Computes the cosine similarity between the user profile and all item profiles\n",
    "        euclidean_similarities = euclidean_distances(user_profiles[person_id], tfidf_matrix)\n",
    "        # Gets the top similar items\n",
    "        similar_indices = euclidean_similarities.argsort().flatten()[-topn:]\n",
    "        # Sort the similar items by similarity\n",
    "        similar_items = sorted([(item_ids[i], euclidean_similarities[0,i]) for i in similar_indices], key=lambda x: -x[1])\n",
    "        return similar_items\n",
    "    \n",
    "class ContentBasedRecommenderManhattan(ContentBasedRecommenderCosineSimilarity):\n",
    "    \n",
    "    def _get_similar_items_to_user_profile(self, person_id, topn=1000):\n",
    "        # Computes the cosine similarity between the user profile and all item profiles\n",
    "        manhattan_similarities = manhattan_distances(user_profiles[person_id], tfidf_matrix)\n",
    "        # Gets the top similar items\n",
    "        similar_indices = manhattan_similarities.argsort().flatten()[-topn:]\n",
    "        # Sort the similar items by similarity\n",
    "        similar_items = sorted([(item_ids[i], manhattan_similarities[0,i]) for i in similar_indices], key=lambda x: -x[1])\n",
    "        return similar_items\n",
    "\n",
    "class ContentBasedRecommenderPolynomialKernel(ContentBasedRecommenderCosineSimilarity):\n",
    "    \n",
    "    def _get_similar_items_to_user_profile(self, person_id, topn=1000):\n",
    "        # Computes the cosine similarity between the user profile and all item profiles\n",
    "        polynomial_similarities = polynomial_kernel(user_profiles[person_id], tfidf_matrix)\n",
    "        # Gets the top similar items\n",
    "        similar_indices = polynomial_similarities.argsort().flatten()[-topn:]\n",
    "        # Sort the similar items by similarity\n",
    "        similar_items = sorted([(item_ids[i], polynomial_similarities[0,i]) for i in similar_indices], key=lambda x: -x[1])\n",
    "        return similar_items\n",
    "    \n",
    "    \n",
    "content_based_recommender_model_cosine = ContentBasedRecommenderCosineSimilarity(filtered_articles)\n",
    "content_based_recommender_model_euclidean = ContentBasedRecommenderEuclidean(filtered_articles)\n",
    "content_based_recommender_model_manhattan = ContentBasedRecommenderManhattan(filtered_articles)\n",
    "content_based_recommender_model_polynomial_kernel = ContentBasedRecommenderPolynomialKernel(filtered_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HXEXoTXMZsff"
   },
   "source": [
    "### Recommendations for a single user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "id": "Q06aXgo5Tple",
    "outputId": "cf127de4-f68f-4650-b246-32410aaee0a3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NewsID</th>\n",
       "      <th>recStrength</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Category</th>\n",
       "      <th>SubCategory</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N1445</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>23841</td>\n",
       "      <td>sports</td>\n",
       "      <td>football_nfl</td>\n",
       "      <td>NFL bust Ryan Leaf explained 's worried Baker ...</td>\n",
       "      <td>Time worry Baker Mayfield ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N60659</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>3085</td>\n",
       "      <td>sports</td>\n",
       "      <td>football_nfl</td>\n",
       "      <td>Texans CB Bradley Roby questionable return Chi...</td>\n",
       "      <td>Houston Texans cornerback Bradley Roby questio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N54042</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>8497</td>\n",
       "      <td>movies</td>\n",
       "      <td>movienews</td>\n",
       "      <td>Jennifer Hudson Transforms Into Aretha Frankli...</td>\n",
       "      <td>Jennifer Hudson Transforms Aretha Franklin Biopic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N52331</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>14052</td>\n",
       "      <td>sports</td>\n",
       "      <td>basketball_nba</td>\n",
       "      <td>Preview : Nuggets wrap preseason Blazers</td>\n",
       "      <td>One count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N10935</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>660</td>\n",
       "      <td>foodanddrink</td>\n",
       "      <td>recipes</td>\n",
       "      <td>Pizza Hut Is Testing Out Round Pizza Boxes Tha...</td>\n",
       "      <td>Why square ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>N40773</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>14739</td>\n",
       "      <td>video</td>\n",
       "      <td>peopleandplaces</td>\n",
       "      <td>Baltimore Buzz | Here 's What 's Trending In B...</td>\n",
       "      <td>Baltimore Buzz | Here 's What 's Trending In B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>N53407</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>26587</td>\n",
       "      <td>sports</td>\n",
       "      <td>football_nfl</td>\n",
       "      <td>3 Studs , 3 Duds Chargers ' loss Steelers</td>\n",
       "      <td>Chargers Wire 's Gavino Borquez lay shined fol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>N6465</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>29130</td>\n",
       "      <td>sports</td>\n",
       "      <td>mma</td>\n",
       "      <td>Swanson advises Gracie : 'Be humble , train ev...</td>\n",
       "      <td>UFC veteran Cub Swanson word advice Kron Graci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>N37025</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>11054</td>\n",
       "      <td>sports</td>\n",
       "      <td>football_nfl</td>\n",
       "      <td>Robert Kraft honor Bill Belichick 300th career...</td>\n",
       "      <td>Belichick earned 300th career win Sunday Patri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>N34240</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>468</td>\n",
       "      <td>sports</td>\n",
       "      <td>football_nfl</td>\n",
       "      <td>Patriots cut QB Cody Kessler flurry roster move</td>\n",
       "      <td>They 're 2 QBs .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NewsID  recStrength  Unnamed: 0      Category      SubCategory  \\\n",
       "0   N1445     1.414214       23841        sports     football_nfl   \n",
       "1  N60659     1.414214        3085        sports     football_nfl   \n",
       "2  N54042     1.414214        8497        movies        movienews   \n",
       "3  N52331     1.414214       14052        sports   basketball_nba   \n",
       "4  N10935     1.414214         660  foodanddrink          recipes   \n",
       "5  N40773     1.414214       14739         video  peopleandplaces   \n",
       "6  N53407     1.414214       26587        sports     football_nfl   \n",
       "7   N6465     1.414214       29130        sports              mma   \n",
       "8  N37025     1.414214       11054        sports     football_nfl   \n",
       "9  N34240     1.414214         468        sports     football_nfl   \n",
       "\n",
       "                                               Title  \\\n",
       "0  NFL bust Ryan Leaf explained 's worried Baker ...   \n",
       "1  Texans CB Bradley Roby questionable return Chi...   \n",
       "2  Jennifer Hudson Transforms Into Aretha Frankli...   \n",
       "3           Preview : Nuggets wrap preseason Blazers   \n",
       "4  Pizza Hut Is Testing Out Round Pizza Boxes Tha...   \n",
       "5  Baltimore Buzz | Here 's What 's Trending In B...   \n",
       "6          3 Studs , 3 Duds Chargers ' loss Steelers   \n",
       "7  Swanson advises Gracie : 'Be humble , train ev...   \n",
       "8  Robert Kraft honor Bill Belichick 300th career...   \n",
       "9    Patriots cut QB Cody Kessler flurry roster move   \n",
       "\n",
       "                                            Abstract  \n",
       "0                        Time worry Baker Mayfield ?  \n",
       "1  Houston Texans cornerback Bradley Roby questio...  \n",
       "2  Jennifer Hudson Transforms Aretha Franklin Biopic  \n",
       "3                                          One count  \n",
       "4                                       Why square ?  \n",
       "5  Baltimore Buzz | Here 's What 's Trending In B...  \n",
       "6  Chargers Wire 's Gavino Borquez lay shined fol...  \n",
       "7  UFC veteran Cub Swanson word advice Kron Graci...  \n",
       "8  Belichick earned 300th career win Sunday Patri...  \n",
       "9                                   They 're 2 QBs .  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recs_cos = content_based_recommender_model_cosine.recommend_items(my_user_id)\n",
    "recs = content_based_recommender_model_euclidean.recommend_items(my_user_id)\n",
    "recs.set_index('NewsID')\n",
    "pd.merge(recs, filtered_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "noVOdKnwQUfL"
   },
   "source": [
    "## Evaluation Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "aRev-YH9kGRX"
   },
   "outputs": [],
   "source": [
    "def get_items_interacted(person_id, interactions_df):\n",
    "    # Get the user's data and merge in the news information.\n",
    "    interacted_items = interactions_df.loc[person_id]['NewsID']\n",
    "    return set(interacted_items if type(interacted_items) == pd.Series else [interacted_items])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JPBMK82zq1X4",
    "outputId": "840e0dc2-e087-40db-be69-b318e993479b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39726, 6)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_articles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "vlWB2mubmjiY"
   },
   "outputs": [],
   "source": [
    "# Top-N accuracy metrics consts\n",
    "EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS = 100\n",
    "\n",
    "class ModelEvaluator:\n",
    "    def get_not_interacted_items_sample(self, person_id, sample_size, seed=42):\n",
    "        interacted_items = get_items_interacted(person_id, behaviours_full_indexed_df)\n",
    "        all_items = set(filtered_articles['NewsID'])\n",
    "        non_interacted_items = all_items - interacted_items\n",
    "\n",
    "        random.seed(seed)\n",
    "        non_interacted_items_sample = random.sample(non_interacted_items, sample_size)\n",
    "        return set(non_interacted_items_sample)\n",
    "\n",
    "    def _verify_hit_top_n(self, item_id, recommended_items, topn):      \n",
    "        try:\n",
    "            index = next(i for i, c in enumerate(recommended_items) if c == item_id)\n",
    "        except Exception as e:\n",
    "            index = -1\n",
    "        hit = int(index in range(0, topn))\n",
    "        return hit, index\n",
    "\n",
    "    def evaluate_model_for_user(self, model, person_id):\n",
    "        # Getting the items in test set\n",
    "        interacted_values_testset = behaviours_test_indexed_df.loc[person_id]\n",
    "        if type(interacted_values_testset['NewsID']) == pd.Series:\n",
    "            person_interacted_items_testset = set(interacted_values_testset['NewsID'])\n",
    "        else:\n",
    "            person_interacted_items_testset = set([interacted_values_testset['NewsID']])  \n",
    "        interacted_items_count_testset = len(person_interacted_items_testset) \n",
    "\n",
    "        # Getting a ranked recommendation list from a model for a given user\n",
    "        person_recs_df = model.recommend_items(\n",
    "            person_id, \n",
    "            items_to_ignore=get_items_interacted(person_id, behaviours_train_indexed_df), \n",
    "            topn=10000000000, ignore_interacted=False)\n",
    "        \n",
    "        hits_at_5_count = 0\n",
    "        hits_at_10_count = 0\n",
    "        # For each item the user has interacted in test set\n",
    "        for item_id in person_interacted_items_testset:\n",
    "            # Getting a random sample (100) items the user has not interacted \n",
    "            # (to represent items that are assumed to be no relevant to the user)\n",
    "            non_interacted_items_sample = self.get_not_interacted_items_sample(person_id, \n",
    "                                                                          sample_size=EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS, \n",
    "                                                                          seed=random.randint(0, 2**32))\n",
    "\n",
    "            # Combining the current interacted item with the 100 random items\n",
    "            items_to_filter_recs = non_interacted_items_sample.union(set([item_id]))\n",
    "\n",
    "            # Filtering only recommendations that are either the interacted item or from a random sample of 100 non-interacted items\n",
    "            valid_recs_df = person_recs_df[person_recs_df['NewsID'].isin(items_to_filter_recs)]                    \n",
    "            valid_recs = valid_recs_df['NewsID'].values\n",
    "            # Verifying if the current interacted item is among the Top-N recommended items\n",
    "            hit_at_5, index_at_5 = self._verify_hit_top_n(item_id, valid_recs, 5)\n",
    "            hits_at_5_count += hit_at_5\n",
    "            hit_at_10, index_at_10 = self._verify_hit_top_n(item_id, valid_recs, 10)\n",
    "            hits_at_10_count += hit_at_10\n",
    "\n",
    "        # Recall is the rate of the interacted items that are ranked among the Top-N recommended items, \n",
    "        # when mixed with a set of non-relevant items\n",
    "        recall_at_5 = hits_at_5_count / float(interacted_items_count_testset)\n",
    "        recall_at_10 = hits_at_10_count / float(interacted_items_count_testset)\n",
    "\n",
    "        person_metrics = {'hits@5_count': hits_at_5_count, \n",
    "                          'hits@10_count': hits_at_10_count, \n",
    "                          'interacted_count': interacted_items_count_testset,\n",
    "                          'recall@5': recall_at_5,\n",
    "                          'recall@10': recall_at_10}\n",
    "        return person_metrics\n",
    "\n",
    "    def evaluate_model(self, model):\n",
    "        print('Running evaluation for users')\n",
    "        people_metrics = []\n",
    "        for idx, person_id in enumerate(list(behaviours_test_indexed_df.index.unique().values)):\n",
    "            if idx % 100 == 0 and idx > 0:\n",
    "               print('%d users processed' % idx)\n",
    "            person_metrics = self.evaluate_model_for_user(model, person_id)  \n",
    "            person_metrics['_person_id'] = person_id\n",
    "            people_metrics.append(person_metrics)\n",
    "        print('%d users processed' % idx)\n",
    "\n",
    "        detailed_results_df = pd.DataFrame(people_metrics) \\\n",
    "                            .sort_values('interacted_count', ascending=False)\n",
    "        \n",
    "        global_recall_at_5 = detailed_results_df['hits@5_count'].sum() / float(detailed_results_df['interacted_count'].sum())\n",
    "        global_recall_at_10 = detailed_results_df['hits@10_count'].sum() / float(detailed_results_df['interacted_count'].sum())\n",
    "        \n",
    "        global_metrics = {'modelName': model.get_model_name(),\n",
    "                          'recall@5': global_recall_at_5,\n",
    "                          'recall@10': global_recall_at_10}    \n",
    "        return global_metrics, detailed_results_df\n",
    "    \n",
    "model_evaluator = ModelEvaluator()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UbwpK5txaDNE"
   },
   "source": [
    "Reduce the test data set to 3000 elements to reduce computation time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "F_RU3OWnLIM1"
   },
   "outputs": [],
   "source": [
    "behaviours_test_indexed_df_full = behaviours_test_indexed_df.copy()\n",
    "behaviours_test_indexed_df = behaviours_test_indexed_df[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UbnyzNllLNwq",
    "outputId": "db03fc81-8397-4a8a-ef85-cf06194e6d5d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(behaviours_test_indexed_df.index.values.tolist()))\n",
    "behaviours_test_indexed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "BnsLnL_eQIaZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Content-Based Filtering model...\n",
      "Running evaluation for users\n",
      "100 users processed\n",
      "200 users processed\n",
      "300 users processed\n",
      "400 users processed\n",
      "500 users processed\n",
      "600 users processed\n",
      "700 users processed\n",
      "800 users processed\n",
      "900 users processed\n",
      "1000 users processed\n",
      "1100 users processed\n",
      "1200 users processed\n",
      "1300 users processed\n",
      "1400 users processed\n",
      "1500 users processed\n",
      "1600 users processed\n",
      "1700 users processed\n",
      "1800 users processed\n",
      "1900 users processed\n",
      "1924 users processed\n"
     ]
    }
   ],
   "source": [
    "print('Evaluating Content-Based Filtering model...')\n",
    "cb_global_metrics, cb_detailed_results_df = model_evaluator.evaluate_model(content_based_recommender_model_cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 732
    },
    "id": "otKqK4ay15ZV",
    "outputId": "ab26a4c3-80b9-4249-e03f-4688397c6341"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Global metrics:\n",
      "{'modelName': 'Content-Based', 'recall@5': 0.1515, 'recall@10': 0.244}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hits@5_count</th>\n",
       "      <th>hits@10_count</th>\n",
       "      <th>interacted_count</th>\n",
       "      <th>recall@5</th>\n",
       "      <th>recall@10</th>\n",
       "      <th>_person_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1924</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U91514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U35649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U90520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U40227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U23596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U75864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U54306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U66947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U20241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U29879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U70925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U6055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U15185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U62092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U42623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U6010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U9798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U74800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U77581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U71886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      hits@5_count  hits@10_count  interacted_count  recall@5  recall@10  \\\n",
       "1924             1              1                 1       1.0        1.0   \n",
       "935              1              1                 1       1.0        1.0   \n",
       "1486             0              1                 1       0.0        1.0   \n",
       "980              1              1                 1       1.0        1.0   \n",
       "1216             0              1                 1       0.0        1.0   \n",
       "982              1              1                 1       1.0        1.0   \n",
       "27               1              1                 1       1.0        1.0   \n",
       "1475             1              1                 1       1.0        1.0   \n",
       "987              0              1                 1       0.0        1.0   \n",
       "20               1              1                 1       1.0        1.0   \n",
       "929              0              1                 1       0.0        1.0   \n",
       "931              1              1                 1       1.0        1.0   \n",
       "1497             0              1                 1       0.0        1.0   \n",
       "1126             1              1                 1       1.0        1.0   \n",
       "1138             0              1                 1       0.0        1.0   \n",
       "933              0              1                 1       0.0        1.0   \n",
       "1135             1              1                 1       1.0        1.0   \n",
       "978              1              1                 1       1.0        1.0   \n",
       "1483             1              1                 1       1.0        1.0   \n",
       "33               1              1                 1       1.0        1.0   \n",
       "\n",
       "     _person_id  \n",
       "1924     U91514  \n",
       "935      U35649  \n",
       "1486     U90520  \n",
       "980      U40227  \n",
       "1216     U23596  \n",
       "982      U75864  \n",
       "27       U54306  \n",
       "1475     U66947  \n",
       "987      U20241  \n",
       "20       U29879  \n",
       "929      U70925  \n",
       "931       U6055  \n",
       "1497     U15185  \n",
       "1126     U62092  \n",
       "1138     U42623  \n",
       "933       U6010  \n",
       "1135      U9798  \n",
       "978      U74800  \n",
       "1483     U77581  \n",
       "33       U71886  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('\\nGlobal metrics:\\n%s' % cb_global_metrics)\n",
    "cb_detailed_results_df.sort_values('recall@10', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Content-Based Filtering model...\n",
      "Running evaluation for users\n",
      "100 users processed\n",
      "200 users processed\n",
      "300 users processed\n",
      "400 users processed\n",
      "500 users processed\n",
      "600 users processed\n",
      "700 users processed\n",
      "800 users processed\n",
      "900 users processed\n",
      "1000 users processed\n",
      "1100 users processed\n",
      "1200 users processed\n",
      "1300 users processed\n",
      "1400 users processed\n",
      "1500 users processed\n",
      "1600 users processed\n",
      "1700 users processed\n",
      "1800 users processed\n",
      "1900 users processed\n",
      "1924 users processed\n"
     ]
    }
   ],
   "source": [
    "print('Evaluating Content-Based Filtering model...')\n",
    "cb_global_metrics, cb_detailed_results_df = model_evaluator.evaluate_model(content_based_recommender_model_euclidean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Global metrics:\n",
      "{'modelName': 'Content-Based', 'recall@5': 0.035, 'recall@10': 0.0645}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hits@5_count</th>\n",
       "      <th>hits@10_count</th>\n",
       "      <th>interacted_count</th>\n",
       "      <th>recall@5</th>\n",
       "      <th>recall@10</th>\n",
       "      <th>_person_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U5141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U36584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U62111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U19644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U92546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U33894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U2140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U62119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U22751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U88975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U22840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U32056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U74929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U72350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U35868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U19139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U78576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U13600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U39819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U93175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      hits@5_count  hits@10_count  interacted_count  recall@5  recall@10  \\\n",
       "1597             1              1                 1       1.0        1.0   \n",
       "1107             1              1                 1       1.0        1.0   \n",
       "1052             0              1                 1       0.0        1.0   \n",
       "1017             0              1                 1       0.0        1.0   \n",
       "1015             1              1                 1       1.0        1.0   \n",
       "1007             1              1                 1       1.0        1.0   \n",
       "930              0              1                 1       0.0        1.0   \n",
       "997              1              1                 1       1.0        1.0   \n",
       "934              0              1                 1       0.0        1.0   \n",
       "740              1              1                 1       1.0        1.0   \n",
       "1023             0              1                 1       0.0        1.0   \n",
       "781              1              1                 1       1.0        1.0   \n",
       "789              1              1                 1       1.0        1.0   \n",
       "793              0              1                 1       0.0        1.0   \n",
       "1180             1              1                 1       1.0        1.0   \n",
       "798              0              1                 1       0.0        1.0   \n",
       "752              0              1                 1       0.0        1.0   \n",
       "766              1              1                 1       1.0        1.0   \n",
       "1206             0              1                 1       0.0        1.0   \n",
       "836              1              1                 1       1.0        1.0   \n",
       "\n",
       "     _person_id  \n",
       "1597      U5141  \n",
       "1107     U36584  \n",
       "1052     U62111  \n",
       "1017     U19644  \n",
       "1015     U92546  \n",
       "1007     U33894  \n",
       "930       U2140  \n",
       "997      U62119  \n",
       "934      U22751  \n",
       "740      U88975  \n",
       "1023     U22840  \n",
       "781      U32056  \n",
       "789      U74929  \n",
       "793      U72350  \n",
       "1180     U35868  \n",
       "798      U19139  \n",
       "752      U78576  \n",
       "766      U13600  \n",
       "1206     U39819  \n",
       "836      U93175  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('\\nGlobal metrics:\\n%s' % cb_global_metrics)\n",
    "cb_detailed_results_df.sort_values('recall@10', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Content-Based Filtering model...\n",
      "Running evaluation for users\n",
      "100 users processed\n",
      "200 users processed\n",
      "300 users processed\n",
      "400 users processed\n",
      "500 users processed\n",
      "600 users processed\n",
      "700 users processed\n",
      "800 users processed\n",
      "900 users processed\n",
      "1000 users processed\n",
      "1100 users processed\n",
      "1200 users processed\n",
      "1300 users processed\n",
      "1400 users processed\n",
      "1500 users processed\n",
      "1600 users processed\n",
      "1700 users processed\n",
      "1800 users processed\n",
      "1900 users processed\n",
      "1924 users processed\n"
     ]
    }
   ],
   "source": [
    "print('Evaluating Content-Based Filtering model...')\n",
    "cb_global_metrics, cb_detailed_results_df = model_evaluator.evaluate_model(content_based_recommender_model_manhattan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Global metrics:\n",
      "{'modelName': 'Content-Based', 'recall@5': 0.0045, 'recall@10': 0.012}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hits@5_count</th>\n",
       "      <th>hits@10_count</th>\n",
       "      <th>interacted_count</th>\n",
       "      <th>recall@5</th>\n",
       "      <th>recall@10</th>\n",
       "      <th>_person_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U27570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U41818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1381</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U90962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U36050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U10547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1835</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U42797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U75498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U30001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U69856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U50919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U40250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U22601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U92624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U61183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U76725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U73019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1878</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U19296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U32164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U88389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1534</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U57166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      hits@5_count  hits@10_count  interacted_count  recall@5  recall@10  \\\n",
       "1525             0              1                 1       0.0        1.0   \n",
       "605              0              1                 1       0.0        1.0   \n",
       "1381             0              1                 1       0.0        1.0   \n",
       "19               1              1                 1       1.0        1.0   \n",
       "331              0              1                 1       0.0        1.0   \n",
       "1835             1              1                 1       1.0        1.0   \n",
       "1272             1              1                 1       1.0        1.0   \n",
       "1204             1              1                 1       1.0        1.0   \n",
       "732              0              1                 1       0.0        1.0   \n",
       "1033             1              1                 1       1.0        1.0   \n",
       "590              1              1                 1       1.0        1.0   \n",
       "891              0              1                 1       0.0        1.0   \n",
       "1678             0              1                 1       0.0        1.0   \n",
       "729              1              1                 1       1.0        1.0   \n",
       "1202             0              1                 1       0.0        1.0   \n",
       "602              0              1                 1       0.0        1.0   \n",
       "1878             0              1                 1       0.0        1.0   \n",
       "413              1              1                 1       1.0        1.0   \n",
       "357              0              1                 1       0.0        1.0   \n",
       "1534             1              1                 1       1.0        1.0   \n",
       "\n",
       "     _person_id  \n",
       "1525     U27570  \n",
       "605      U41818  \n",
       "1381     U90962  \n",
       "19       U36050  \n",
       "331      U10547  \n",
       "1835     U42797  \n",
       "1272     U75498  \n",
       "1204     U30001  \n",
       "732      U69856  \n",
       "1033     U50919  \n",
       "590      U40250  \n",
       "891      U22601  \n",
       "1678     U92624  \n",
       "729      U61183  \n",
       "1202     U76725  \n",
       "602      U73019  \n",
       "1878     U19296  \n",
       "413      U32164  \n",
       "357      U88389  \n",
       "1534     U57166  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('\\nGlobal metrics:\\n%s' % cb_global_metrics)\n",
    "cb_detailed_results_df.sort_values('recall@10', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Content-Based Filtering model...\n",
      "Running evaluation for users\n",
      "100 users processed\n",
      "200 users processed\n",
      "300 users processed\n",
      "400 users processed\n",
      "500 users processed\n",
      "600 users processed\n",
      "700 users processed\n",
      "800 users processed\n",
      "900 users processed\n",
      "1000 users processed\n",
      "1100 users processed\n",
      "1200 users processed\n",
      "1300 users processed\n",
      "1400 users processed\n",
      "1500 users processed\n",
      "1600 users processed\n",
      "1700 users processed\n",
      "1800 users processed\n",
      "1900 users processed\n",
      "1924 users processed\n"
     ]
    }
   ],
   "source": [
    "print('Evaluating Content-Based Filtering model...')\n",
    "cb_global_metrics, cb_detailed_results_df = model_evaluator.evaluate_model(content_based_recommender_model_polynomial_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Global metrics:\n",
      "{'modelName': 'Content-Based', 'recall@5': 0.1575, 'recall@10': 0.243}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hits@5_count</th>\n",
       "      <th>hits@10_count</th>\n",
       "      <th>interacted_count</th>\n",
       "      <th>recall@5</th>\n",
       "      <th>recall@10</th>\n",
       "      <th>_person_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1924</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U91514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U33445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U66947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U74800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U40227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U75864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U23596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U71886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U54306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U20241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U15185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U70925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U54762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U6055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U25857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U6010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U62092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U90520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U15912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>U77581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      hits@5_count  hits@10_count  interacted_count  recall@5  recall@10  \\\n",
       "1924             1              1                 1       1.0        1.0   \n",
       "792              1              1                 1       1.0        1.0   \n",
       "1475             1              1                 1       1.0        1.0   \n",
       "978              1              1                 1       1.0        1.0   \n",
       "980              1              1                 1       1.0        1.0   \n",
       "982              1              1                 1       1.0        1.0   \n",
       "1216             0              1                 1       0.0        1.0   \n",
       "33               1              1                 1       1.0        1.0   \n",
       "27               0              1                 1       0.0        1.0   \n",
       "987              0              1                 1       0.0        1.0   \n",
       "1497             0              1                 1       0.0        1.0   \n",
       "929              0              1                 1       0.0        1.0   \n",
       "22               0              1                 1       0.0        1.0   \n",
       "931              0              1                 1       0.0        1.0   \n",
       "1500             1              1                 1       1.0        1.0   \n",
       "933              0              1                 1       0.0        1.0   \n",
       "1126             1              1                 1       1.0        1.0   \n",
       "1486             0              1                 1       0.0        1.0   \n",
       "1224             1              1                 1       1.0        1.0   \n",
       "1483             1              1                 1       1.0        1.0   \n",
       "\n",
       "     _person_id  \n",
       "1924     U91514  \n",
       "792      U33445  \n",
       "1475     U66947  \n",
       "978      U74800  \n",
       "980      U40227  \n",
       "982      U75864  \n",
       "1216     U23596  \n",
       "33       U71886  \n",
       "27       U54306  \n",
       "987      U20241  \n",
       "1497     U15185  \n",
       "929      U70925  \n",
       "22       U54762  \n",
       "931       U6055  \n",
       "1500     U25857  \n",
       "933       U6010  \n",
       "1126     U62092  \n",
       "1486     U90520  \n",
       "1224     U15912  \n",
       "1483     U77581  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('\\nGlobal metrics:\\n%s' % cb_global_metrics)\n",
    "cb_detailed_results_df.sort_values('recall@10', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "News Recommender System. Lopushanskyy, Savchuk.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
